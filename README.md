
# ğŸ§  PrivatePrompt

A full-stack offline AI application that connects frontend and backend layers with local LLMs like LLaMA, OpenHermes, and more.

## ğŸ“ Project Structure

```
PrivatePrompt/
â”œâ”€â”€ Backend/       # FastAPI backend with RAG, LLM chat, and session handling
â”œâ”€â”€ Frontend/      # React + Tailwind CSS chat UI
â”œâ”€â”€ .gitignore     # Files ignored by Git
â””â”€â”€ README.md      # Project documentation
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/koppolu-buddha-bhavan/PrivatePrompt.git
cd PrivatePrompt
```

---

### 2. Run the Backend

```bash
cd Backend
# Install Python dependencies
pip install -r requirements.txt

# Start FastAPI server
uvicorn main:app --reload
```

---

### 3. Run the Frontend

```bash
cd ../Frontend
npm install
npm run dev
```

---

## ğŸ›  Tech Stack

- **Frontend**: React, Tailwind CSS, Vite
- **Backend**: FastAPI (Python)
- **LLM Support**: Local models via Ollama (LLaMA3, CodeLLaMA, OpenHermes)
- **Database**: SQLite or TinyDB (for sessions/chat)

---

## â— Git Submodule Fix (If Needed)

If Git throws an error like `Frontend is a submodule`, run the following from the root:

```bash
git rm --cached Frontend
rm -rf .gitmodules
rm -rf .git/config  # âš ï¸ use only if necessary
cp -r /actual/path/to/Frontend ./Frontend
git add Frontend
git commit -m "Fixed submodule issue"
git push
```

---

## âœ¨ Features

- Chat UI with streaming response
- Local-only secure processing
- RAG pipeline support
- Model switch per session

---

## ğŸ‘¨â€ğŸ’» Author

**Koppolu Buddha Bhavan**  
ğŸ“ [GitHub](https://github.com/koppolu-buddha-bhavan)

---
